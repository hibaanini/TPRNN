{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#!pip install datasets torch tensorboard\n","metadata":{"id":"oqaGX7eV4a4t","trusted":true,"execution":{"iopub.status.busy":"2025-12-25T08:51:29.418899Z","iopub.execute_input":"2025-12-25T08:51:29.419485Z","iopub.status.idle":"2025-12-25T08:51:29.422854Z","shell.execute_reply.started":"2025-12-25T08:51:29.419455Z","shell.execute_reply":"2025-12-25T08:51:29.422130Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.tensorboard import SummaryWriter\nfrom datasets import load_dataset\nimport numpy as np","metadata":{"id":"h1WLMsRB9iF4","trusted":true,"execution":{"iopub.status.busy":"2025-12-25T08:51:29.423907Z","iopub.execute_input":"2025-12-25T08:51:29.424135Z","iopub.status.idle":"2025-12-25T08:51:29.436809Z","shell.execute_reply.started":"2025-12-25T08:51:29.424114Z","shell.execute_reply":"2025-12-25T08:51:29.436182Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"#Chargement du dataset\nfrom datasets import load_dataset\n\ndataset = load_dataset(\"sander-wood/irishman\")\n\ntrain_data = dataset[\"train\"]\nval_data = dataset[\"validation\"]\n\nprint(\"Nombre de chansons (train) :\", len(train_data))\nprint(\"Nombre de chansons (validation) :\", len(val_data))\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iTPq5n7X6NmP","outputId":"2a13f75c-f1c5-4423-da6d-129d9d066b5a","trusted":true,"execution":{"iopub.status.busy":"2025-12-25T08:51:29.437912Z","iopub.execute_input":"2025-12-25T08:51:29.438139Z","iopub.status.idle":"2025-12-25T08:51:30.492183Z","shell.execute_reply.started":"2025-12-25T08:51:29.438118Z","shell.execute_reply":"2025-12-25T08:51:30.491583Z"}},"outputs":[{"name":"stdout","text":"Nombre de chansons (train) : 214122\nNombre de chansons (validation) : 2162\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"print(train_data[0][\"abc notation\"])\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1buB2VTn8lmX","outputId":"2790adeb-8eb5-467c-a4a5-c306c5e4491d","trusted":true,"execution":{"iopub.status.busy":"2025-12-25T08:51:30.493530Z","iopub.execute_input":"2025-12-25T08:51:30.493802Z","iopub.status.idle":"2025-12-25T08:51:30.497841Z","shell.execute_reply.started":"2025-12-25T08:51:30.493780Z","shell.execute_reply":"2025-12-25T08:51:30.497182Z"}},"outputs":[{"name":"stdout","text":"X:1\nL:1/8\nM:4/4\nK:Emin\n|: E2 EF E2 EF | DEFG AFDF | E2 EF E2 B2 |1 efe^d e2 e2 :|2 efe^d e3 B |: e2 ef g2 fe | \n defg afdf |1 e2 ef g2 fe | efe^d e3 B :|2 g2 bg f2 af | efe^d e2 e2 ||\n","output_type":"stream"}],"execution_count":46},{"cell_type":"markdown","source":"**Prétraitement des données**","metadata":{"id":"eta1vY3r8peP"}},{"cell_type":"code","source":"#Extraction des caractères uniques\ntrain_songs = [item[\"abc notation\"] for item in train_data]\n\nall_text = \"\".join(train_songs)\nvocab = sorted(set(all_text))\n\nprint(\"Nombre de caractères uniques :\", len(vocab))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"57KV-Ti28nXn","outputId":"271a6000-4907-42b1-f016-9630b09d866a","trusted":true,"execution":{"iopub.status.busy":"2025-12-25T08:51:30.498624Z","iopub.execute_input":"2025-12-25T08:51:30.498876Z","iopub.status.idle":"2025-12-25T08:51:34.702940Z","shell.execute_reply.started":"2025-12-25T08:51:30.498855Z","shell.execute_reply":"2025-12-25T08:51:34.702365Z"}},"outputs":[{"name":"stdout","text":"Nombre de caractères uniques : 95\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"#Mapping caractères ↔ indices\nchar2idx = {c: i for i, c in enumerate(vocab)}\nidx2char = {i: c for c, i in char2idx.items()}","metadata":{"id":"FjBpo9Dv8xTZ","trusted":true,"execution":{"iopub.status.busy":"2025-12-25T08:51:34.704565Z","iopub.execute_input":"2025-12-25T08:51:34.704838Z","iopub.status.idle":"2025-12-25T08:51:34.708660Z","shell.execute_reply.started":"2025-12-25T08:51:34.704817Z","shell.execute_reply":"2025-12-25T08:51:34.707920Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"#Vectorisation des chaînes\ndef vectorize_string(s, char2idx):\n    return [char2idx[c] for c in s]\n\ntest_vec = vectorize_string(train_songs[0], char2idx)\nprint(test_vec[:20])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yuiIY84n83v_","outputId":"a7145243-892f-4b3e-d527-43f9aa17b350","trusted":true,"execution":{"iopub.status.busy":"2025-12-25T08:51:34.709478Z","iopub.execute_input":"2025-12-25T08:51:34.709661Z","iopub.status.idle":"2025-12-25T08:51:34.723371Z","shell.execute_reply.started":"2025-12-25T08:51:34.709642Z","shell.execute_reply":"2025-12-25T08:51:34.722655Z"}},"outputs":[{"name":"stdout","text":"[56, 26, 17, 0, 44, 26, 17, 15, 24, 0, 45, 26, 20, 15, 20, 0, 43, 26, 37, 77]\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"#Padding des séquences\nmax_len = max(len(song) for song in train_songs)\nprint(\"Longueur maximale :\", max_len)\n\ndef pad_sequence(s, max_len, pad_char=\" \"):\n    if len(s) < max_len:\n        return s + pad_char * (max_len - len(s))\n    else:\n        return s[:max_len]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5T3VgxLa851a","outputId":"5563a3fc-9d89-457b-df58-fdc54dd45268","trusted":true,"execution":{"iopub.status.busy":"2025-12-25T08:51:34.724258Z","iopub.execute_input":"2025-12-25T08:51:34.724767Z","iopub.status.idle":"2025-12-25T08:51:34.768853Z","shell.execute_reply.started":"2025-12-25T08:51:34.724745Z","shell.execute_reply":"2025-12-25T08:51:34.768100Z"}},"outputs":[{"name":"stdout","text":"Longueur maximale : 2968\n","output_type":"stream"}],"execution_count":50},{"cell_type":"markdown","source":"**Création du Dataset PyTorch**","metadata":{"id":"vrgZIxmt9ERK"}},{"cell_type":"code","source":"#Préparation finale des données\ndef prepare_data(songs, char2idx, max_len):\n    sequences = []\n    for song in songs:\n        padded = pad_sequence(song, max_len)\n        vectorized = vectorize_string(padded, char2idx)\n        sequences.append(vectorized)\n    return sequences\n\ntrain_sequences = prepare_data(train_songs, char2idx, max_len)\nval_sequences = prepare_data(\n    [item[\"abc notation\"] for item in val_data],\n    char2idx,\n    max_len\n)\n","metadata":{"id":"Wyjk7EPU8-_H","trusted":true,"execution":{"iopub.status.busy":"2025-12-25T08:51:34.769683Z","iopub.execute_input":"2025-12-25T08:51:34.769915Z","iopub.status.idle":"2025-12-25T08:52:07.886470Z","shell.execute_reply.started":"2025-12-25T08:51:34.769895Z","shell.execute_reply":"2025-12-25T08:52:07.885842Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nimport torch\n\nclass MusicDataset(Dataset):\n    def __init__(self, sequences, pad_idx, max_len):\n        self.pad_idx = pad_idx\n        self.max_len = max_len\n        self.data = [self.pad_or_truncate(seq) for seq in sequences]\n        self.data = torch.tensor(self.data, dtype=torch.long)\n\n    def pad_or_truncate(self, seq):\n        if len(seq) > self.max_len:\n            return seq[:self.max_len]\n        else:\n            return seq + [self.pad_idx] * (self.max_len - len(seq))\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        seq = self.data[idx]\n        x = seq[:-1]   # entrée\n        y = seq[1:]    # cible décalée\n        return x, y\nBATCH_SIZE = 8\nMAX_LEN = 300\nPAD_IDX = char2idx[\" \"]   # très important\n\ntrain_dataset = MusicDataset(train_sequences, PAD_IDX, MAX_LEN)\nval_dataset   = MusicDataset(val_sequences, PAD_IDX, MAX_LEN)\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n\n# Vérification\nx, y = next(iter(train_loader))\nprint(x.shape, y.shape)  # (8, MAX_LEN-1)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z3qTfaCx9Jpf","outputId":"95d672bf-d428-4684-8c30-8eb870acd87e","trusted":true,"execution":{"iopub.status.busy":"2025-12-25T08:52:07.887249Z","iopub.execute_input":"2025-12-25T08:52:07.887481Z","iopub.status.idle":"2025-12-25T08:52:13.355749Z","shell.execute_reply.started":"2025-12-25T08:52:07.887459Z","shell.execute_reply":"2025-12-25T08:52:13.354928Z"}},"outputs":[{"name":"stdout","text":"torch.Size([8, 299]) torch.Size([8, 299])\n","output_type":"stream"}],"execution_count":52},{"cell_type":"markdown","source":"**Implémentation du modèle LSTM**","metadata":{"id":"Q2gRtamZ-FL_"}},{"cell_type":"code","source":"import torch.nn as nn\n\nclass MusicRNN(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_size, pad_idx):\n        super().__init__()\n\n        self.embedding = nn.Embedding(\n            vocab_size,\n            embedding_dim,\n            padding_idx=pad_idx\n        )\n\n        self.lstm = nn.LSTM(\n            embedding_dim,\n            hidden_size,\n            batch_first=True\n        )\n\n        self.fc = nn.Linear(hidden_size, vocab_size)\n\n    def forward(self, x):\n        x = self.embedding(x)\n        out, _ = self.lstm(x)\n        out = self.fc(out)\n        return out\n","metadata":{"id":"kSrwl41K9_oI","trusted":true,"execution":{"iopub.status.busy":"2025-12-25T08:52:13.356728Z","iopub.execute_input":"2025-12-25T08:52:13.357063Z","iopub.status.idle":"2025-12-25T08:52:13.362759Z","shell.execute_reply.started":"2025-12-25T08:52:13.357040Z","shell.execute_reply":"2025-12-25T08:52:13.362002Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"# Hyperparamètres demandés (adaptés pour 1 epoch)\nEMBEDDING_DIM = 256\nHIDDEN_SIZE = 512      # plus léger que 1024\nLEARNING_RATE = 5e-3\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = MusicRNN(\n    vocab_size=len(char2idx),\n    embedding_dim=EMBEDDING_DIM,\n    hidden_size=HIDDEN_SIZE,\n    pad_idx=PAD_IDX\n)\n\nmodel.to(device)\n","metadata":{"id":"OVW0oxgf-amg","trusted":true,"execution":{"iopub.status.busy":"2025-12-25T08:52:13.364496Z","iopub.execute_input":"2025-12-25T08:52:13.364711Z","iopub.status.idle":"2025-12-25T08:52:13.470410Z","shell.execute_reply.started":"2025-12-25T08:52:13.364690Z","shell.execute_reply":"2025-12-25T08:52:13.469714Z"}},"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"MusicRNN(\n  (embedding): Embedding(95, 256, padding_idx=1)\n  (lstm): LSTM(256, 512, batch_first=True)\n  (fc): Linear(in_features=512, out_features=95, bias=True)\n)"},"metadata":{}}],"execution_count":54},{"cell_type":"code","source":"def train_one_epoch(model, train_loader, val_loader, lr, pad_idx):\n    criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n    writer = SummaryWriter()\n\n    # ===== TRAIN =====\n    model.train()\n    train_loss = 0\n\n    for x, y in train_loader:\n        x, y = x.to(device), y.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(x)\n\n        loss = criterion(\n            outputs.view(-1, outputs.size(-1)),\n            y.view(-1)\n        )\n\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n\n    train_loss /= len(train_loader)\n\n    # ===== VALIDATION =====\n    model.eval()\n    val_loss = 0\n\n    with torch.no_grad():\n        for x, y in val_loader:\n            x, y = x.to(device), y.to(device)\n            outputs = model(x)\n            loss = criterion(\n                outputs.view(-1, outputs.size(-1)),\n                y.view(-1)\n            )\n            val_loss += loss.item()\n\n    val_loss /= len(val_loader)\n\n    writer.add_scalars(\"Loss\", {\"Train\": train_loss, \"Val\": val_loss}, 0)\n    writer.close()\n\n    torch.save(model.state_dict(), \"model_1_epoch.pth\")\n\n    print(f\"Train Loss : {train_loss:.4f} | Val Loss : {val_loss:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-25T08:52:13.471371Z","iopub.execute_input":"2025-12-25T08:52:13.471742Z","iopub.status.idle":"2025-12-25T08:52:13.479209Z","shell.execute_reply.started":"2025-12-25T08:52:13.471709Z","shell.execute_reply":"2025-12-25T08:52:13.478528Z"}},"outputs":[],"execution_count":55},{"cell_type":"markdown","source":"**Génération de musique**","metadata":{"id":"a4C566ha-mh5"}},{"cell_type":"code","source":"train_one_epoch(\n    model=model,\n    train_loader=train_loader,\n    val_loader=val_loader,\n    lr=LEARNING_RATE,\n    pad_idx=PAD_IDX\n)\n","metadata":{"id":"JaifDzHV-s24","trusted":true,"execution":{"iopub.status.busy":"2025-12-25T08:52:13.480195Z","iopub.execute_input":"2025-12-25T08:52:13.480504Z","iopub.status.idle":"2025-12-25T09:05:55.014118Z","shell.execute_reply.started":"2025-12-25T08:52:13.480472Z","shell.execute_reply":"2025-12-25T09:05:55.013383Z"}},"outputs":[{"name":"stdout","text":"Train Loss : 1.2787 | Val Loss : 1.2816\n","output_type":"stream"}],"execution_count":56},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom music21 import converter, midi\n\n# =====================\n# Fonction de génération\n# =====================\ndef generate_music(model, start_seq, char2idx, idx2char, length=200, pad_idx=None):\n    model.eval()\n    device = next(model.parameters()).device\n\n    input_seq = torch.tensor(\n        [char2idx.get(c, pad_idx) for c in start_seq],\n        dtype=torch.long\n    ).unsqueeze(0).to(device)\n\n    generated = start_seq\n\n    with torch.no_grad():\n        for _ in range(length):\n            output = model(input_seq)\n            probs = F.softmax(output[0, -1], dim=0)\n            next_idx = torch.multinomial(probs, 1).item()\n            next_char = idx2char[next_idx]\n\n            generated += next_char\n            input_seq = torch.cat(\n                [input_seq, torch.tensor([[next_idx]], device=device)],\n                dim=1\n            )\n\n    return generated\n\n# =====================\n# Générer la musique\n# =====================\nstart_seq = (\n    \"X:1\\n\"\n    \"T:Generated Tune\\n\"\n    \"M:4/4\\n\"\n    \"K:C\\n\"\n)\n\ngenerated_music = generate_music(\n    model=model,\n    start_seq=start_seq,\n    char2idx=char2idx,\n    idx2char=idx2char,\n    length=200,\n    pad_idx=PAD_IDX\n)\n\nprint(\"=== Musique générée ===\")\nprint(generated_music)\n\n# =====================\n# Sauvegarder en fichier .abc\n# =====================\nwith open(\"generated_music.abc\", \"w\") as f:\n    f.write(generated_music)\nprint(\"Fichier ABC créé : generated_music.abc\")\n\n# =====================\n# Convertir en MIDI et jouer\n# =====================\nabc_stream = converter.parse(\"generated_music.abc\")\nmf = midi.translate.streamToMidiFile(abc_stream)\nmf.open(\"generated_music.mid\", \"wb\")\nmf.write()\nmf.close()\nprint(\"Fichier MIDI créé : generated_music.mid\")\n\n# Jouer directement (si possible sur votre machine)\nabc_stream.show('midi')\n","metadata":{"id":"QscxGMqq-u5k","colab":{"base_uri":"https://localhost:8080/","height":211},"outputId":"c3ec999a-5e51-4032-91cf-62388496cf48","trusted":true,"execution":{"iopub.status.busy":"2025-12-25T09:09:24.200407Z","iopub.execute_input":"2025-12-25T09:09:24.200961Z","iopub.status.idle":"2025-12-25T09:09:26.364395Z","shell.execute_reply.started":"2025-12-25T09:09:24.200932Z","shell.execute_reply":"2025-12-25T09:09:26.363816Z"}},"outputs":[{"name":"stdout","text":"=== Musique générée ===\nX:1\nT:Generated Tune\nM:4/4\nK:C\n|:\"C\"\"^A\"\"A\"Bb/ag/\"^/\"\"C\"m\"B/\"_=\"g<d\"C\".F/.E/).G<c\"G\"\"G\"F/\"G\"\"G\"Bg\"D\"\"Am\"{B}ed/\"A\"A/B/c/d/\"Bb\"|\"Em\"{cB}\"Ab\"Bef\"B7\"\"D\"Ag\"D\"A/B/c/d/\"E\"\"^C\"B,\"Bb\"Bb\"Bb\"G\"B<b\"E\"E\"B\"B<E\"Em\"B/\"E\"B7\"Be\"B\"Bg\"D\"\"A\"Ece\"E\"e/f/\"\nFichier ABC créé : generated_music.abc\nFichier MIDI créé : generated_music.mid\n","output_type":"stream"},{"name":"stderr","text":"abcFormat: WARNING: Could not get pitch information from note:  m, assuming C\nabcFormat: WARNING: Could not get pitch information from note:  _=, assuming C\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n        <div id=\"midiPlayerDiv552\"></div>\n        <link rel=\"stylesheet\" href=\"https://cuthbertLab.github.io/music21j/css/m21.css\">\n        \n        <script\n        src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\"\n        ></script>\n    \n        <script>\n        function midiPlayerDiv552_play() {\n            const rq = require.config({\n                paths: {\n                    'music21': 'https://cuthbertLab.github.io/music21j/releases/music21.debug',\n                }\n            });\n            rq(['music21'], function(music21) {\n                mp = new music21.miditools.MidiPlayer();\n                mp.addPlayer(\"#midiPlayerDiv552\");\n                mp.base64Load(\"data:audio/midi;base64,TVRoZAAAAAYAAQACJ2BNVHJrAAAAGgD/UQMHoSAA/1kCAAAA/1gEBAIYCM5g/y8ATVRyawAAAi8A/wMAAOAAQM5ggDAAAIA0AACANwAAkDBaAJA0WgCQN1oAkEdapzCARwAAkFNak1iAUwAAkFFapzCAUQAAkE9ak1iATwAAkDxapzCAPAAAkDxapzCAPAAAkDxapzCAPAAAkENapzCAQwAAkENapzCAQwAAkENapzCAQwAAkENapzCAQwAAkD5apzCAPgAAkEVapzCARQAAkEVapzCARQAAkEdapzCARwAAkFNapzCAUwAAkEBapzCAQAAAkEVapzCARQAAkFNapzCAUwAAkEdagpNQgEcAAJA+WqcwgD4AAJA+WqcwgD4AAJBAWqcwgEAAAJA9WqcwgD0AAIAvAACAMwAAgDYAAJAvWgCQM1oAkDZaAJBHWqcwgEcAAJBTWqcwgFMAAIAuAACAMgAAgDUAAJAuWgCQMloAkDVaAJBHWqcwgEcAAJBTWqcwgFMAAIA3AACAOwAAgD4AAJA3WgCQO1oAkD5aAJBHWpNYgEcAAJBTWrsIgFMAAIA0AACAOAAAgDsAAJA0WgCQOFoAkDtaAJBAWqcwgEAAAIAvAACAMwAAgDYAAJAvWgCQM1oAkDZaAJBHWpNYgEcAAJBAWrsIgEAAAIA0AACANwAAgDsAAJA0WgCQN1oAkDtaAJBHWpNYgEcAAIA0AACAOAAAgDsAAJA0WgCQOFoAkDtaAJBHWoKTUIBHAACQR1qnMIBHAACQPlqnMIA+AACQRVqnMIBFAACQQFqnMIBAAM5g/y8A\");\n            });\n        }\n        if (typeof require === 'undefined') {\n            setTimeout(midiPlayerDiv552_play, 2000);\n        } else {\n            midiPlayerDiv552_play();\n        }\n        </script>"},"metadata":{}}],"execution_count":59},{"cell_type":"code","source":"# BONUS : Augmentation des données musicales\n# Étape 1 : Définir les notes musicales ABC\n\nABC_NOTES = ['C', 'D', 'E', 'F', 'G', 'A', 'B']\n\n# Étape 2 : Fonction de transposition\n\ndef transpose_abc(song, shift=1):\n    result = \"\"\n    for c in song:\n        if c in ABC_NOTES:\n            idx = ABC_NOTES.index(c)\n            result += ABC_NOTES[(idx + shift) % len(ABC_NOTES)]\n        else:\n            result += c\n    return result\n\n# Étape 3 : Augmenter le dataset par transposition\n\ndef augment_by_transposition(songs):\n    augmented = []\n    for song in songs:\n        augmented.append(song)                      # chanson originale\n        augmented.append(transpose_abc(song, 1))   # transposition vers le haut\n        augmented.append(transpose_abc(song, -1))  # transposition vers le bas\n    return augmented\n\n# Étape 4 : Utilisation\ntrain_songs_augmented = augment_by_transposition(train_songs)\n\nprint(\"Avant augmentation :\", len(train_songs))\nprint(\"Après augmentation :\", len(train_songs_augmented))\n","metadata":{"id":"GNjNGRq6AB-y","trusted":true,"execution":{"iopub.status.busy":"2025-12-25T09:05:55.023341Z","iopub.execute_input":"2025-12-25T09:05:55.023624Z","iopub.status.idle":"2025-12-25T09:06:15.939092Z","shell.execute_reply.started":"2025-12-25T09:05:55.023595Z","shell.execute_reply":"2025-12-25T09:06:15.938491Z"}},"outputs":[{"name":"stdout","text":"Avant augmentation : 214122\nAprès augmentation : 642366\n","output_type":"stream"}],"execution_count":58}]}